{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import multiprocessing\n",
    "from multiprocessing.dummy import Pool\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from skimage import feature\n",
    "from PIL import Image, ImageOps\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from scipy.stats import moment\n",
    "\n",
    "from skimage.restoration import denoise_wavelet\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2train = 'data/train/'\n",
    "path2test = 'data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = img_height=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPUs: 7\n"
     ]
    }
   ],
   "source": [
    "cpu_count = 2*multiprocessing.cpu_count()-1\n",
    "print('Number of CPUs: {}'.format(cpu_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(img, row=0, col=0, center=True):\n",
    "    \n",
    "    '''img = resizeImage(img) # cant resize the image!!\n",
    "    img = RGB2Gray(img) #cant transform to rgb!'''\n",
    "    \n",
    "    if center:\n",
    "        img = crop_image_center(img)\n",
    "    else:\n",
    "        img = crop_image_corners(img, row=row, col=col)\n",
    "\n",
    "    img = localBinaryPatterns(img)\n",
    "    #img = img - filter_median(img)\n",
    "    #img = img - filter_wavelet(img)\n",
    "    img = noise_wavelet(img)\n",
    "    #img = vectorizeImage(img, nb_channels=3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_corners(img, row, col, img_width=128, img_height=128):\n",
    "\n",
    "    width, height = img.size   # Get dimensions\n",
    "\n",
    "    x = row*(width-img_width)\n",
    "    y = col*(height-img_height)\n",
    "    crop = img.crop((x, y, x + img_width, y + img_height))\n",
    "    \n",
    "    return crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_center(img, img_width=128, img_height=128):\n",
    "    width, height = img.size   # Get dimensions\n",
    "\n",
    "    left = (width - img_width)/2\n",
    "    top = (height - img_height)/2\n",
    "    right = (width + img_width)/2\n",
    "    bottom = (height + img_height)/2\n",
    "\n",
    "    crop = img.crop((left, top, right, bottom))\n",
    "    return crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomCropImage(img, img_width=128, img_height=128):\n",
    "    \n",
    "    width, height = img.size   # Get dimensions\n",
    "\n",
    "    idx_width = random.randint(0, width - img_width)\n",
    "    idx_height = random.randint(0, height - img_height)\n",
    "\n",
    "    return img.crop((idx_width, idx_height, idx_width+img_width, idx_height + img_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizeImage(img, img_width=128, img_height=128, nb_channels = 1):\n",
    "    return img.reshape(-1,img_width * img_height * nb_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_median(img, factor=2):\n",
    "    return ndimage.median_filter(img, factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_wavelet(img):\n",
    "    return denoise_wavelet(img=img, multichannel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizeImage(img, img_width=128, img_height=128):\n",
    "    img = img.resize((img_width, img_height))\n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localBinaryPatterns(img, numPoints=24, radius=2):\n",
    "    \n",
    "    img_lbp = np.zeros(np.array(img).shape)\n",
    "    for i in range(np.array(img).shape[2]):\n",
    "        img_lbp[:,:,i] = feature.local_binary_pattern(img.getchannel(i), numPoints,\n",
    "                    radius, method=\"uniform\")\n",
    "    return img_lbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise_wavelet(img, n_moments=9):\n",
    "    \n",
    "    res = []\n",
    "    for i in range(0, img.shape[2]):\n",
    "        coeffs = pywt.dwt2(img[:,:,i], wavelet='haar')\n",
    "        cA, (cH, cV, cD) = coeffs\n",
    "\n",
    "        for j in range(0, n_moments):\n",
    "            res.append(moment(cH.ravel(), moment=j))\n",
    "            res.append(moment(cV.ravel(), moment=j))\n",
    "            res.append(moment(cD.ravel(), moment=j))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB2Gray(img):\n",
    "    img = np.array(img)\n",
    "    return np.dot(img[...,:3], [0.299, 0.587, 0.114]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractImage(path, row=0, col=0, center=True, isTrain = True):\n",
    "\n",
    "    with Image.open(path) as img:\n",
    "        img = preProcessing(img, row, col, center)\n",
    "    if isTrain:\n",
    "        target = path.split('/')[-2]\n",
    "    else:\n",
    "        target = path.split('/')[-1]\n",
    "    return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractImage_helper(args):\n",
    "    return extractImage(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractImagesParallel(path_lst, row=0, col=0, center=True, isTrain=True, threads=2):\n",
    "    pool = Pool(threads)\n",
    "    #imgs, targets = zip(*pool.map(extractImage, path))\n",
    "    #result = pool.map(extractImage, path_lst)\n",
    "    job_args = [(path, row, col, center, isTrain) for path in path_lst] \n",
    "    result = pool.map(extractImage_helper, job_args)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path, row=0, col=0, center=True, nb_threads=2, format_file = '*.jpg', isTrain = True):\n",
    "    results = []\n",
    "\n",
    "    for subdir, dirs, files in os.walk(path):\n",
    "        if subdir.split('/')[-1] != '':\n",
    "\n",
    "            print('Reading files from dir: {}'.format(subdir))\n",
    "\n",
    "            path_folder = os.path.join(subdir, format_file)\n",
    "            filesPath = glob.glob(path_folder) \n",
    "\n",
    "            res  = extractImagesParallel(filesPath, row, col, center, isTrain, threads=nb_threads)\n",
    "            results.append(res)\n",
    "    \n",
    "    flattened_list = [y for x in results for y in x]\n",
    "    X, y = map(list, zip(*flattened_list))\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    if np.array(X).shape[1] == 1:\n",
    "        X = np.squeeze(X, axis=1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''params = {'center': {\n",
    "            'row': 0, 'col': 0, 'center': True\n",
    "            },\n",
    "          'rb': {\n",
    "            'row': 1, 'col': 0, 'center': False\n",
    "            },\n",
    "          'lb': {\n",
    "            'row': 0, 'col': 0, 'center': False\n",
    "            },\n",
    "          'rh': {\n",
    "            'row': 0, 'col': 1, 'center': False\n",
    "            },\n",
    "          'lh': {\n",
    "            'row': 1, 'col': 1, 'center': False\n",
    "            }\n",
    "         }'''\n",
    "params = {'center': {\n",
    "            'row': 0, 'col': 0, 'center': True\n",
    "            }\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nX_dict = {}\\ny_dict = {}\\n\\nX_test_dict = {}\\n\\nfor k, v in params.items():\\n    params_lst = []\\n    for k1, v1 in v.items():\\n        params_lst.append(v1)\\n    \\n    print('\\nReading training data for {} image...\\n'.format(k))\\n    X_dict[k], y_dict[k] = get_data(path2train, row=params_lst[0], col=params_lst[1],\\n                                        center=params_lst[2], nb_threads=cpu_count)\\n    \\n    print('\\nReading testing data for {} image...\\n'.format(k))\\n    X_test_dict[k], _ = get_data(path2test,  row=params_lst[0], col=params_lst[1],\\n                                        center=params_lst[2], nb_threads=cpu_count, format_file='*.tif', is_train=False)\\n\""
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "X_dict = {}\n",
    "y_dict = {}\n",
    "\n",
    "X_test_dict = {}\n",
    "\n",
    "for k, v in params.items():\n",
    "    params_lst = []\n",
    "    for k1, v1 in v.items():\n",
    "        params_lst.append(v1)\n",
    "    \n",
    "    print('\\nReading training data for {} image...\\n'.format(k))\n",
    "    X_dict[k], y_dict[k] = get_data(path2train, row=params_lst[0], col=params_lst[1],\n",
    "                                        center=params_lst[2], nb_threads=cpu_count)\n",
    "    \n",
    "    print('\\nReading testing data for {} image...\\n'.format(k))\n",
    "    X_test_dict[k], _ = get_data(path2test,  row=params_lst[0], col=params_lst[1],\n",
    "                                        center=params_lst[2], nb_threads=cpu_count, format_file='*.tif', is_train=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training data...\n",
      "\n",
      "Reading files from dir: data/train/iPhone-4s\n",
      "Reading files from dir: data/train/Motorola-Droid-Maxx\n",
      "Reading files from dir: data/train/HTC-1-M7\n",
      "Reading files from dir: data/train/Samsung-Galaxy-S4\n",
      "Reading files from dir: data/train/Motorola-X\n",
      "Reading files from dir: data/train/Motorola-Nexus-6\n",
      "Reading files from dir: data/train/LG-Nexus-5x\n"
     ]
    }
   ],
   "source": [
    "print('Reading training data...\\n')\n",
    "X, y = get_data(path2train, nb_threads=cpu_count)\n",
    "print('Reading testing data...')\n",
    "X_test, filename_test = get_data(path2test, format_file='*.tif', isTrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of the training data X: {}, y: {}'.format(X_train.shape, y_train.shape))\n",
    "print('Shape of the valid data X: {}, y: {}'.format(X_valid.shape, y_valid.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_type = 'zScore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Normalization type: {}'.format(normalization_type))\n",
    "\n",
    "if normalization_type == 'minMax':\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "elif normalization_type == 'zScore':        \n",
    "    scaler =  StandardScaler()\n",
    "    \n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = linear_model.LogisticRegression(max_iter=10)\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(lr_model.score(X_train, y_train)))\n",
    "print('Accuracy of logistic regression classifier on valid set: {:.2f}'.format(lr_model.score(X_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model = MLPClassifier(hidden_layer_sizes=(256,), max_iter=100, alpha=1e-4,\n",
    "                    solver='sgd', verbose=0, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp_model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of logistic regression classifier on train set: {:.2f}'.format(mlp_model.score(X_train, y_train)))\n",
    "print('Accuracy of logistic regression classifier on valid set: {:.2f}'.format(mlp_model.score(X_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_lr = confusion_matrix(y_valid, y_pred_lr)\n",
    "cm_mlp = confusion_matrix(y_valid, y_pred_mlp)\n",
    "\n",
    "#http://scikit-learn.org/stable/auto_examples/neural_networks/plot_mnist_filters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(cm, title='Confusion matrix', cmap=None, normalize=True):\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "plt.subplot(1,2,1)\n",
    "plot_cm(cm_lr)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plot_cm(cm_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission_file(fname, predictions, info='cama_model'):\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    \n",
    "    submission_df = pd.DataFrame()\n",
    "    submission_df['fname'] = fname\n",
    "    submission_df['camera'] = [x for x in predictions]\n",
    "    \n",
    "    if not os.path.isdir('subm'):\n",
    "        os.mkdir('subm')\n",
    "    suffix = info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "    sub_file = os.path.join('subm', 'submission_' + suffix + '.csv')\n",
    "    submission_df.to_csv(sub_file, index=False)\n",
    "    print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_mlp = mlp_model.predict(X_test)\n",
    "y_pred_test_lr = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_submission_file(filename_test, y_pred_test_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showCamaraTransformations():\n",
    "\n",
    "    plt.figure(figsize=(20,5))\n",
    "    path = 'data/train/iPhone-4s/(iP4s)9.jpg'\n",
    "    with Image.open(path) as img:\n",
    "        plt.subplot(1,3,1)\n",
    "        img = RGB2Gray(img)\n",
    "        img_wav = denoise_wavelet(img)\n",
    "        plt.imshow(np.round(img-img_wav), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1,3,2)\n",
    "        img_mean = median_filter(img, factor=4)\n",
    "        plt.imshow(np.round(img-img_mean), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1,3,3)\n",
    "        img_lbp = localBinaryPatterns(img)\n",
    "        plt.imshow(img_lbp, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        \n",
    "#showCamaraTransformations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "path = 'data/train/iPhone-4s/(iP4s)9.jpg'\n",
    "with Image.open(path) as img:\n",
    "    coeffs = pywt.dwt2(img, 'haar')\n",
    "    cA, (cH, cV, cD) = coeffs\n",
    "print('cA {}'.format(cA.shape) )\n",
    "print('cH: {}'.format(cH.shape) )\n",
    "print('cV: {}'.format(cV.shape) )\n",
    "print('cD: {}'.format(cD.shape) )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''path = 'data/train/iPhone-4s/(iP4s)9.jpg'\n",
    "img = Image.open(path)\n",
    "plt.imshow(crop_image_corners(img, row=1, col=0))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(X).shape)\n",
    "img_wav_filtered = denoise_wavelet(X, multichannel=True, convert2ycbcr=True,  mode='soft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import glob, os\n",
    "folder = 'data/train/Sony-NEX-7'\n",
    "for filename in glob.iglob(os.path.join(folder, '*.JPG')):\n",
    "    os.rename(filename, filename[:-4] + '.jpg')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showCamaraPhotos(X, y=[], is_train =True, img_width=128, img_height=128, nb_channels = 1):\n",
    "\n",
    "    idx = random.randint(0,len(X))\n",
    "    if is_train:\n",
    "        plt.title(y[idx])\n",
    "    img = X[idx].reshape(img_width, img_height, nb_channels)\n",
    "    if nb_channels == 1:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.figure(figsize=(20,5))\n",
    "for i in range(0, 3):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    showCamaraPhotos(X, y, nb_channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
