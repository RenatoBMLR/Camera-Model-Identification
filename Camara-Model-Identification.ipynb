{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torch.optim as optim\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CamaraModelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path2data, transforms=None, is_train = False):\n",
    "        \n",
    "\n",
    "        self.transform = transforms \n",
    "        \n",
    "        self.X= []\n",
    "        self.y = []\n",
    "        count = 0\n",
    "        labels = {}\n",
    "        for subdir, dirs, files in os.walk(path):\n",
    "            if subdir.split('/')[-1] != '':\n",
    "                labels[count] = subdir.split('/')[-1]\n",
    "                path_folder = os.path.join(subdir, '*.jpg')\n",
    "                files = glob.glob(path_folder) \n",
    "                self.X.extend(files)\n",
    "                self.y.extend(np.full((1, len(files)), count, dtype=int)[0])\n",
    "                \n",
    "                count = count + 1\n",
    "                \n",
    "        self.labels = labels\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        path = self.X[index]\n",
    "        label = self.y[index]\n",
    "\n",
    "        with open(path, 'rb') as f:\n",
    "            flbase = os.path.basename(path)\n",
    "            \n",
    "            with Image.open(f) as img:\n",
    "                 image = img.convert('RGB')\n",
    "                    \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Image2Vector(object):\n",
    "\n",
    "    def __call__(self, image):\n",
    "\n",
    "        image = np.asarray(image)\n",
    "        image = np.reshape(image, (image.shape[0]*image.shape[1], image.shape[2]))\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SpatialFiltering(object):\n",
    "    \n",
    "    def __call__(self, image):\n",
    "\n",
    "        image = image - image.mean()\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width = img_height=128\n",
    "nb_channels = 3\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((img_width, img_height)),\n",
    "        transforms.ToTensor(),\n",
    "        SpatialFiltering()\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'data/flowers/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "n_epochs = 100\n",
    "learningRate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = {'train': CamaraModelDataset(path, transforms=data_transforms['train'],  is_train = True)}\n",
    "dloader ={'train': torch.utils.data.DataLoader(dsets['train'], batch_size=batch_size, shuffle=True)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dsets['train'].labels\n",
    "print('Labels of the dataset: {}'.format(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(image, mean=imagenet_mean, std=imagenet_std):\n",
    "    inp = image.transpose((1, 2, 0))  # Channel Last\n",
    "    img = std * inp + mean\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CamaraPhotos(dsets, labels):\n",
    "    \n",
    "    rand_img = random.randrange(0, len(dsets))\n",
    "    img, y = dsets[rand_img]\n",
    "    img = img.numpy()\n",
    "    img = img.transpose((1, 2, 0))  # Channel Last\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    plt.title('Label: {}'.format(labels[int(y)]))\n",
    "\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "for i in range(0, 3):\n",
    "    plt.subplot(1,3,i+1)\n",
    "\n",
    "    CamaraPhotos(dsets['train'], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size = nb_channels*img_width*img_height\n",
    "num_classes = len(labels)\n",
    "\n",
    "model = LogisticRegression(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(size_average=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    for i, (images, labels) in enumerate(dloader['train']):\n",
    "        images = Variable(images.view(-1, nb_channels*img_width*img_height))\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print ('Epoch: [%d/%d], Loss: %.4f' \n",
    "           % (epoch+1, n_epochs, loss.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "for plotIndex, badIndex in enumerate(misclassifiedIndexes[0:5]):\n",
    "    plt.subplot(1, 5, plotIndex + 1)\n",
    "    plt.imshow(np.reshape(X_test[badIndex], (20,20)), cmap=plt.cm.gray)\n",
    "    plt.axis('off')\n",
    "    plt.title('Predicted: {}, Actual: {}'.format(predictions[badIndex], y_test[badIndex]), fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
