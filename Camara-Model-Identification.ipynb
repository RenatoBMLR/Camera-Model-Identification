{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from scipy import misc\n",
    "from scipy import ndimage\n",
    "from skimage import feature\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CamaraModelDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path2data, transforms=None, is_train = False, is_test=False):\n",
    "        \n",
    "        self.transform = transforms \n",
    "        \n",
    "        self.X= []\n",
    "        self.y = []\n",
    "        count = 0\n",
    "        labels = {}\n",
    "        for subdir, dirs, files in os.walk(path):\n",
    "            if subdir.split('/')[-1] != '':\n",
    "                labels[count] = subdir.split('/')[-1]\n",
    "                path_folder = os.path.join(subdir, '*.jpg')\n",
    "                files = glob.glob(path_folder) \n",
    "                self.X.extend(files)\n",
    "                self.y.extend(np.full((1, len(files)), count, dtype=int)[0])\n",
    "                \n",
    "                count = count + 1\n",
    "                \n",
    "        self.labels = labels\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        path = self.X[index]\n",
    "        label = self.y[index]\n",
    "\n",
    "        with open(path, 'rb') as f:\n",
    "            flbase = os.path.basename(path)\n",
    "            \n",
    "            with Image.open(f) as img:\n",
    "                 image = img.convert('RGB')\n",
    "                    \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RGB2Gray(object):\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        image = np.array(image)\n",
    "        return np.dot(image[...,:3], [0.299, 0.587, 0.114])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps=1e-7\n",
    "numPoints = 24\n",
    "radius = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LocalBinaryPatterns(object):\n",
    "\n",
    "        def __call__(self, image):\n",
    "\n",
    "            lbp = feature.local_binary_pattern(image, numPoints,\n",
    "                        radius, method=\"uniform\")\n",
    "\n",
    "            (hist, _) = np.histogram(lbp.ravel(),\n",
    "                bins=np.arange(0, numPoints + 3),\n",
    "                range=(0, numPoints + 2))\n",
    "\n",
    "            # normalize the histogram\n",
    "            hist = hist.astype(\"float\")\n",
    "            hist /= (hist.sum() + eps)\n",
    "\n",
    "            return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width = img_height=128\n",
    "nb_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((img_width, img_height)),\n",
    "        RGB2Gray(),\n",
    "        LocalBinaryPatterns(),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'data/flowers/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dsets = {'train': CamaraModelDataset(path, transforms=data_transforms['train'],  is_train = True),\n",
    "         'valid': CamaraModelDataset(path, transforms=data_transforms['train'],  is_train = True),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_seed = 3\n",
    "shuffle = True\n",
    "valid_size = 0.2\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(dsets['train'])\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "if shuffle:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader ={'train': torch.utils.data.DataLoader(dsets['train'], batch_size=batch_size, sampler=train_sampler),\n",
    "         'valid': torch.utils.data.DataLoader(dsets['valid'], batch_size=batch_size, sampler=valid_sampler)\n",
    "         } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels of the dataset: {0: 'daisy', 1: 'dandelion', 2: 'rose', 3: 'sunflower', 4: 'tulip'}\n"
     ]
    }
   ],
   "source": [
    "labels = dsets['train'].labels\n",
    "print('Labels of the dataset: {}'.format(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CamaraPhotos(dsets, labels):\n",
    "    \n",
    "    rand_img = random.randrange(0, len(dsets))\n",
    "    img, y = dsets[rand_img]\n",
    "    img = img.numpy()\n",
    "    img = img.transpose((1, 2, 0))  # Channel Last\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    plt.title('Label: {}'.format(labels[int(y)]))\n",
    "\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure(figsize=(20,5))\\nfor i in range(0, 3):\\n    plt.subplot(1,3,i+1)\\n\\n    CamaraPhotos(dsets['train'], labels)\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plt.figure(figsize=(20,5))\n",
    "for i in range(0, 3):\n",
    "    plt.subplot(1,3,i+1)\n",
    "\n",
    "    CamaraPhotos(dsets['train'], labels)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input_size = nb_channels*img_width*img_height\n",
    "input_size = numPoints + 2\n",
    "num_classes = len(labels)\n",
    "\n",
    "model = LogisticRegression(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "learningRate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(size_average=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Batchs: 21/28"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    i0 = 0\n",
    "    for i, (features, labels) in enumerate(dloader['train']):\n",
    "    \n",
    "        #features = Variable(features.view(-1, nb_channels*img_width*img_height))\n",
    "        features = Variable(features).float()\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        i0+=1\n",
    "        print('\\rProcessing Batchess: {}/{}'.format(i0, len(dloader['train'])), end='')\n",
    "\n",
    "    print ('\\nEpoch: [%d/%d], Loss: %.4f' \n",
    "           % (epoch+1, n_epochs, loss.data[0]))\n",
    "    \n",
    "print('Execution time {0:.2f} s'.format((datetime.datetime.now() - start_time).total_seconds()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(dset_loaders, model, use_gpu=False):\n",
    "\n",
    "    predictions = []\n",
    "    labels_lst = []\n",
    "    ii_n = len(dset_loaders)\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(dset_loaders):\n",
    "        \n",
    "        if use_gpu:\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "        inputs = Variable(inputs).float()\n",
    "        predictions.append(model(inputs).data)\n",
    "        labels_lst.append(labels)\n",
    "\n",
    "        print('\\rpredict: {}/{}'.format(i, ii_n - 1), end='')\n",
    "    print(' ok')\n",
    "    print('Execution time {0:.2f} s'.format((datetime.datetime.now()- start_time).total_seconds()))\n",
    "    if len(predictions) > 0:\n",
    "        return {'pred': torch.cat(predictions, 0), 'true':torch.cat(labels_lst, 0) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_train = predict(dloader['train'], model)\n",
    "result_valid = predict(dloader['valid'], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getPrediction(result):\n",
    "    _, predicted = torch.max(result['pred'], 1)\n",
    "    result['pred'] = predicted.cpu().numpy()\n",
    "    result['true'] = result['true'].cpu().numpy()\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_train = getPrediction(result_train)\n",
    "result_valid = getPrediction(result_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_train = (result_train['true'] == result_train['pred']).sum()\n",
    "correct_valid = (result_valid['true'] == result_valid['pred']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train: {}/{}'.format(correct_train, len(dloader['train'])*batch_size))\n",
    "print('Valid: {}/{}'.format(correct_valid, len(dloader['valid'])*batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "for plotIndex, badIndex in enumerate(misclassifiedIndexes[0:5]):\n",
    "    plt.subplot(1, 5, plotIndex + 1)\n",
    "    plt.imshow(np.reshape(X_test[badIndex], (20,20)), cmap=plt.cm.gray)\n",
    "    plt.axis('off')\n",
    "    plt.title('Predicted: {}, Actual: {}'.format(predictions[badIndex], y_test[badIndex]), fontsize = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image processing draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = misc.face()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_filtering(mode, image):\n",
    "    \n",
    "    if mode == 'gaussian':\n",
    "        filtered = ndimage.gaussian_filter(image, sigma=3)\n",
    "    elif mode == 'median':\n",
    "        #A median filter preserves better the edges:\n",
    "        #Median filter: better result for straight boundaries (low curvature):\n",
    "\n",
    "        filtered = ndimage.median_filter(image, 2)\n",
    "        \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = image_filtering('gaussian', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(image, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(filtered, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(image - filtered, cmap=plt.cm.gray)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_gray = rgb2gray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the histogram of Local Binary Patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image_gray, cmap=plt.cm.gray)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(lbp, cmap=plt.cm.gray)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
